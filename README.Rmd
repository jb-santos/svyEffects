---
title: "svyEffects"
output: 
  github_document:
    toc: true
    toc_depth: 2
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/"
)
```

```{r, echo = FALSE}
library(tidyverse)
library(ggplot2)
```


## How to install `svyEffects`

Run the code below in an `R` or `RStudio` session, and it will install `{svyEffects}`. You'll need the `{remotes}` package, if you don't already have it (which is why it's included in the code). If you already have it, then just skip the first line. 

```
install.packages("remotes")
library(remotes)
remotes::install_github("jb-santos/svyEffects, force = TRUE")
```

*Note: if you have installed a previous version of this package and want to update,
ensure you include the argument `force = TRUE` in the function call because all 
versions of a GitHub packages are v0.0.0.9000.*


## Introduction

An oft-cited reason why `R` is not more widely used in social science research is its disjointed and incomplete set of tools to deal with weights. `{svyEffects}` helps address this problem by providing a suite of post-estimation tools for working with limited dependent variable models (binary, ordinal, and multinomial logit) estimated on survey-weighted data.

Its main set of functions calculate predicted probabilities using either:

- the *average marginal effects* approach (also known as *marginal effects at observed values*); or 
- the *marginal effects at reasonable/representative/typical values* approach (also known as *marginal effects for the average case*). 

These approaches are analogous to `Stata`'s commands `margins x` and `margins x, at`, respectively.

After calculating predicted probabilities, it will then calculate differences in probabilities (also known as *contrasts*/*pairwise comparisons* for categorical predictors and *first differences* for continuous predictors) using:

- for continuous predictors, the change across the entire range of the variable (by default), or a one-unit change centred on the mean or a one-standard-deviation change centred on the mean; or
- for categorical predictors, all pairwise differences.

For both predictions and differences, it uses simulation methods (the parametric bootstrap) to derive 95% confidence intervals.

It works with the following survey-weighted model objects: `survey::svyglm` (binary logit), `survey::svyolr` (ordered logit), `svrepmisc::svymultinom` (multinomial logit).

Eventually, support for (non-survey) weighted model objects (i.e. models estimated with the `weight` option) will be added for `glm`, `MASS::polr`, and `nnet::multinom`.

Also included in the package are:
 
- A `plot` method that creates a `ggplot` object of predicted probabilities or differences in predicted probabilities. This plot can be modified by adding further `ggplot` commands, which is shown below.
- A function `svyPRE` that calculates the proportional reductions in error for `svyglm` and `svyolr` models (functionality for `svymultinom` models in development).
- A function `mnlSig` that displays a concise summary of multinomial logit coefficients with statistical significance stars. This has been adapted for use on `svymultinom` objects from Dave Armstrong's original function from `{DAMisc}`, which works for `multinom` objects.
- A snippet of the 2019 Canadian Election Study Online Survey for testing and demonstration purposes. This can be loaded with the command `data(ces19)`.


--------------------------------------------------------------------------------


# Development history and differences from other packages

This package extends functions originally written by Dave Armstrong, some of which are in his `{DAMisc}` package (https://github.com/davidaarmstrong/damisc). 

The reporting functions and naming conventions are inspired by Daniel Ludecke's excellent `{ggeffects}` package (https://github.com/strengejacke/ggeffects). Current users of `{ggeffects}` will notice similarities between `{svyEffects}` and `{ggeffects}`. However, while `{ggeffects}` can estimate MER probabilities (what it calls *adjusted predictions*) with `svyglm` objects, it is not compatible with either `svyolr` or `svymultinom` objects. Moreover, `{svyEffects}` estimates true average marginal effects, which is the estimate of a variable's effect on a given outcome at the population level as opposed to a variable's effect for a hypothetical "average case" that may or may not exist or even be theoretically plausible. (A detailed discussion of the difference is in Hanmer and Kalkan 2013, *AJPS*, the full citation of which can be found in the reference section.) 

Note: because AMEs run simulations on multiple copies of your dataset, they can take much more time to calculate than MERs, particularly on large datasets or when using an older computer. Those needing quick results can calculate MERs (which, in practice *usually* substantively similar to AMEs) and then decide from there for which variables they want to calculate AMEs. 


--------------------------------------------------------------------------------


# Binary dependent variable models

To demonstrate how this function works with binary dependent variables, we'll model voting for the Conservative Party of Canada versus voting for any other party.

```{r}
library(svyEffects)
data(ces19)

library(survey)
ces19_svy <- svydesign(ids = ~1, strata = NULL, weights = ~pesweight, 
                       data = ces19, digits = 3)

VOTECON <- svyglm(votecon ~ agegrp + gender + educ + region + relig + marketlib + culturetrad, 
                  design = ces19_svy, family = binomial)
summary(VOTECON)
```

The estimates from `survey::svyglm` closely resemble the ones from `Stata`'s `logit` command with `[pweight=]` specified (see the comparison tables in the Appendix).

## Predictions on a categorical variable

Let's look at the effect of educational attainment (`educ`), a categorical predictor with three levels: high school or less, some post-secondary, and a university degree at the bachelor's level or higher.

The function `svyAME` will return average marginal effects for education, or the effect of a change in education, holding all other variables at observed values. We'll specify a seed value for reproducibility purposes.

The function's output is a list that contains three data frames: 

- `$preds`: predicted probabilities
- `$diffs`: differences in predicted probabilities
- `$seed`: the seed value used for the simulations

```{r}
library(svyEffects)
VOTECON_educ_ame <- svyEffects::svyAME(VOTECON,
                                       varname = "educ",
                                       seed = 2019)
VOTECON_educ_ame$preds
```

Again, the results from `svyAME` match the `Stata` equivalent of `margins` within 0.001 for the mean predicted probability and within 0.002 for the upper and lower 95% confidence bounds (see the relevant table in the Appendix).  

`svyAME` also calculates the differences in predicted probabilities for all pairwise comparisons between levels of our predictor variable. 

```{r}
VOTECON_educ_ame$diffs
```

The differences also compare favourably to the same results from `Stata`. The `svyEffects` and `Stata` results differ by <0.001.


```
. lincom _b[2.educ] - _b[1.educ]

 ( 1)  - 1bn.educ + 2.educ = 0

------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         (1) |   .0044692   .0378337     0.12   0.906    -.0696834    .0786218
------------------------------------------------------------------------------

. lincom _b[3.educ] - _b[1.educ]

 ( 1)  - 1bn.educ + 3.educ = 0

------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         (1) |   .0126461   .0417288     0.30   0.762    -.0691408     .094433
------------------------------------------------------------------------------

. lincom _b[3.educ] - _b[2.educ]

 ( 1)  - 2.educ + 3.educ = 0

------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         (1) |   .0081769   .0302207     0.27   0.787    -.0510547    .0674084
------------------------------------------------------------------------------
```

## Plotting

The outputs of this function lend themselves well to plotting using `{ggplot2}`. As an example, let's plot the predicted probabilities of voting Conservative across levels of education.

```{r}
library(ggplot2)
ggplot(VOTECON_educ_ame$preds) +
  aes(x = educ,
      y = predicted,
      ymin = conf.low,
      ymax = conf.high) +
  geom_pointrange() +
  labs(title = "Probability of voting Conservative by education",
       y = "Predicted probability",
       x = "Education")
```

For convenience, `{svyEffects}` also includes a `plot` method, which uses the `{ggplot2}` engine to visualize either predicted probabilities or differences in predicted probabilities.

By default, the predicted probabilities are plotted, as shown below. 

```{r}
plot(VOTECON_educ_ame)
```

Note that labelling is minimal on the automatically-generated plots, but you can add your own customization using `{ggplot2}`'s code conventions.

```{r}
plot(VOTECON_educ_ame) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "My title",
       subtitle = "My subtitle",
       x = "My xvar label",
       y = "My yvar label",
       caption = "My caption") +
  theme_classic()
```

You can also plot the differences in predicted probabilities between levels of education by including the option `what = "diffs"` (or simply `"diffs"`) in the `plot` function call.

Note, to do this in `Stata`, you would have to calculate each pairwise difference with a separate command. While it is not difficult to write a loop to do that, you would still need to output the results to a separate matrix and then generate the plot. The functions in `svyEffects` do that for you.


```{r}
plot(VOTECON_educ_ame, "diffs") +
  geom_hline(yintercept = 0, linetype = "dotted")
```


## Predictions on a continuous variable

Now, let's look at the effect of market liberalism, a continuous predictor that ranges from -1 (minimal market liberalism, or the most left-wing position) to +1 (maximal market liberalism, or the most right-wing position).


```{r}
VOTECON_marketlib_ame <- svyAME(VOTECON,
                                varname = "marketlib",
                                seed = 2019)
VOTECON_marketlib_ame$preds
```

`svyAME` also produces very similar results to `Stata` for the effect of market liberalism (see Appendix).


```{r}
VOTECON_marketlib_ame$diffs
plot(VOTECON_marketlib_ame)
```


Note that, because the function returns a first difference for continuous predictors, the graph is not any more illuminating than the summary statistic.

```{r, fig.height=3}
plot(VOTECON_marketlib_ame, "diffs")
```


--------------------------------------------------------------------------------


# Ordinal dependent variable models

To demonstrate ordinal dependent variables, we'll model feeling thermometer ratings for the leader of the Conservative Party of Canada. This variable usually ranges from 0 to 100. But, for this example, we'll used a collapsed ordinal measure of "cold" (0-39), "lukewarm" (40-59), and "hot" (60-100). 

```{r}
data(ces19)

library(survey)
ces19_svy <- svydesign(ids = ~1, strata = NULL, weights = ~pesweight, 
                        data = ces19, digits = 3)

CONLDR <- svyolr(ftconldr ~ agegrp + gender + educ + region + relig + marketlib + culturetrad, 
                 design = ces19_svy)
summary(CONLDR)
```


## Predictions on a categorical variable

Here's the effect of region on feelings towards the Conservative Party leader. 

For brevity, only the visualizations of the predicted probabilities/differences are presented, along with comparisons versus `Stata`. Detailed comparison tables can be seen in the Appendix.

```{r}
CONLDR_region_ame <- svyAME(CONLDR,
                            varname = "region",
                            seed = 2019)
plot(CONLDR_region_ame)
```


For ordinal and multinomial probabilities, the plot method follows the conventions used by the `{ggeffects}` package (i.e. facetting by response level). But, you can re-create the `Stata` default of colour-coding the response level by writing your own `ggplot` command, as shown below.

```{r}
ggplot(CONLDR_region_ame$preds) + 
  aes(x = region, y = predicted, ymin = conf.low, ymax = conf.high, colour = y) +
  geom_pointrange(position = position_dodge2(.35)) +
  scale_y_continuous(limits = c(.05,.62)) +
  scale_colour_viridis_d() +
  labs(title = "Effect of region on Conservative leader rating (svyEffects)",
       x = "Region",
       y = "Predicted probability",
       colour = "Conservative \nleader rating") +
  theme_bw()
```

The predicted probabilities for region are very similar to the `Stata` results.


![](images/conldr_region.png)


```{r}
plot(CONLDR_region_ame, "diffs") +
  geom_hline(yintercept = 0, linetype = "dotted")
```


## Predictions on a continuous variable

Here's the effect of market liberalism:

```{r}
CONLDR_marketlib_ame <- svyAME(CONLDR,
                            varname = "marketlib",
                            diffchange = "range",
                            seed = 2019)
plot(CONLDR_marketlib_ame)
```


```{r, fig.height=3}
plot(CONLDR_marketlib_ame, "diffs")
```

The graph below shows the results similar to how `Stata` plots them. 

```{r}
ggplot(CONLDR_marketlib_ame$preds) +
  aes(x = marketlib, y = predicted, ymin = conf.low, ymax = conf.high, colour = y, fill = y) +
  geom_line() +
  geom_ribbon(colour = "transparent", alpha = 0.2) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0, 1, length = 6)) +
  scale_x_continuous(breaks = seq(-1, 1, length = 6)) +
  scale_colour_viridis_d() +
  scale_fill_viridis_d() +
  labs(title = "Effect of market liberalism on Conservative leader ratings (svyEffects)",
       x = "Market liberalism (least to most)",
       y = "Predicted probability",
       fill = "Conservative \nleader rating",
       colour = "Conservative \nleader rating") +
  theme_bw()
```

The `Stata` results are very similar.

![](images/conldr_marketlib.png)

--------------------------------------------------------------------------------


# Multinomial dependent variable models

To demonstrate multinomial dependent variables, we'll model vote choice in the 2019 Canadian Federal Election. To keep things simple, we'll limit our analysis to the three major parties (the Liberals, Conservatives, and New Democrats) and exclude the province of Quebec (which has a different party system and patterns of vote choice).

There is no way to directly estimate a multinomial model with the `{survey}` package in `R`. The package `{svyrepmisc}` generates an approximation by turning the weighting scheme into replicate weights and estimating the model with those. It uses the jackknife to calculate variances.

We'll go through this process step-by-step. First, we'll import the data, do some data cleaning, and then create our usual survey-design object.

```{r}
data(ces19)
library(survey)
ces19_svy <- svydesign(ids = ~1, strata = NULL, weights = ~pesweight, 
                        data = ces19, digits = 3)
```

Now, we'll use the function `as.svrepdesign()` from `{survey}` to turn our sampling weights into replicate weights with variances calculated using the jackknife.

```{r}
ces19_svy_r <- as.svrepdesign(ces19_svy, type = "JK1")
```


After our survey design object with replicate weights and jackknife variances is created, we can use the function `svymultinom` from `{svyrepmisc}` to run our vote choice model. 

Note: use the option `trace = FALSE` in the `svymultinom` function call to suppress the reporting of each replication (similar to using the option `quietly` in Stata).

Included with `{svyEffects}` the function `mnlSig`, which displays coefficients from multinomial logit models and flags statistically significant ones. `mnlSig` is adapted from Dave Armstrong's original function from his `{DAMisc}` package.


```{r}
# remotes::install_github("carlganz/svrepmisc")
library(svrepmisc)

VOTE <- svymultinom(vote ~ agegrp + gender + educ + region + relig + marketlib + culturetrad, 
                    design = ces19_svy_r, trace = FALSE)
mnlSig(VOTE)
```


## Predictions on a categorical variable

For our post-estimation command, we'll need to specify a few more options because `svymultinom` does not store them in its output. These are:

- `design`: the survey design object used to estimate the model; and
- `modform`: the model formula used in the `svymultinom` call (in the form `modform = "y ~ x1 + x2 + x3"`).

Here's the effect of education:

```{r}
VOTE_region_ame <- svyAME(
  VOTE,
  varname = "region",
  weightvar = "pesweight",
  seed = 2019,
  design = ces19_svy_r,
  modform = "vote ~ agegrp + gender + educ + region + relig + marketlib + culturetrad")
VOTE_region_ame$preds
```


```{r}
plot(VOTE_region_ame)
```

The predicted probabilities by region in `Stata` format: 

```{r}
ggplot(VOTE_region_ame$preds) +
  aes(x = region, y = predicted, ymin = conf.low, ymax = conf.high, colour = y) +
  geom_pointrange(position = position_dodge2(.2)) +
  scale_y_continuous(limits = c(.1,.55), breaks = c(.1,.2,.3,.4,.5)) +
  scale_colour_manual(values =  c("maroon", "navy", "orange")) +
  labs(title = "Effect of region on vote choice (svyEffects)",
       x = "Region",
       y = "Predicted probability",
       colour = "Vote choice") +
  theme_bw()
```

And here are the results from `Stata`:

![](images/vote_region.png)

```{r}
plot(VOTE_region_ame, "diffs") +
  geom_hline(yintercept = 0, linetype = "dotted")
```


## Predictions on a continuous variable

Here's the effect of market liberalism:

```{r}
VOTE_marketlib_ame <- svyAME(
  VOTE,
  varname = "marketlib",
  weightvar = "pesweight",
  seed = 2019,
  diffchange = "range",
  design = ces19_svy_r,
  modform = "vote ~ agegrp + gender + educ + region + relig + marketlib + culturetrad")
VOTE_marketlib_ame$preds
plot(VOTE_marketlib_ame)
```

The effect of market liberalism graphed in "`Stata` format":

```{r}
ggplot(VOTE_marketlib_ame$preds) +
  aes(x = marketlib, y = predicted, ymin = conf.low, ymax = conf.high, colour = y, fill = y) +
  geom_line() +
  geom_ribbon(colour = "transparent", alpha = 0.2) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0, 1, length = 6)) +
  scale_x_continuous(breaks = seq(-1, 1, length = 6)) +
  scale_colour_manual(values = c("maroon", "navy", "orange")) +
  scale_fill_manual(values = c("maroon", "navy", "orange")) +
  labs(title = "Effect of market liberalism on vote choice (svyEffects)",
       x = "Market liberalism (least to most)",
       y = "Predicted probability",
       fill = "Vote choice",
       colour = "Vote choice") +
  theme_bw()
```

Here are the results from `Stata`:

![](images/vote_marketlib.png)

Finally, here are the differences:

```{r, fig.height=3}
plot(VOTE_marketlib_ame, "diffs")
```


--------------------------------------------------------------------------------


# Marginal effects at reasonable values

*(documentation in progress)*

You can choose to calculate predicted probabilities and differences using the 
"marginal effects at reasonable/representative values" (MER) approach by using 
the `svyMER` function, which uses the same arguments as `svyAME`. This command 
would give you the estimated effect of a variable "for the 'typical' case" 
(which may or may not be typical, plausible, or even possible in the real world) 
as opposed to the effect of a variable across the population 
(see Hanmer and Kalkan 2013 for an in-depth discussion). 

MER probabilities are *usually* very similar to AME probabilities, but not 
always. However, they are *much* faster to calculate using simulation methods 
because they do not use all cases in the data set.


--------------------------------------------------------------------------------


# Interaction effects

*(documentation in progress)*

Both `svyAME` and `svyMER` support calculating predicted probabilities of 
combinations of two predictor variables. This can be done by using the argument 
`byvar = "x"` in the function call. This works with or without a product term.

This will not return differences in predicted probabilities. For limited-dependent 
variable models, one would need to calculate a second difference  to test for the 
significance of an interaction between two variables, either from the inclusion 
of a product term or through the compression inherent in these types of models 
(see Norton, Wang, and Ai 2004).

Dave Armstrong's `{DAMisc}` package (https://github.com/davidaarmstrong/damisc/)
has an `R` port for Norton, Wang, and Ai's original `Stata` function, and this 
will eventually be ported to `{svyEffects}` and adapted for use in survey-weighted models.


```{r}
VOTECON_educ_region <- svyAME(VOTECON,
                              varname = "educ",
                              byvar = "region",
                              seed = 2019)
VOTECON_educ_region$preds
plot(VOTECON_educ_region)
```

```{r}
VOTECON_marketlib_educ <- svyAME(VOTECON,
                                 varname = "marketlib",
                                 byvar = "educ",
                                 seed = 2019)
VOTECON_marketlib_educ$preds
plot(VOTECON_marketlib_educ)
```


```{r}
VOTECON2 <- svyglm(votecon ~ agegrp + gender + educ + region + relig + marketlib + culturetrad +
                     marketlib:educ, 
                   design = ces19_svy, family = binomial)
VOTECON2_marketlib_educ <- svyAME(VOTECON2,
                                  varname = "marketlib",
                                  byvar = "educ",
                                  seed = 2019)
VOTECON2_marketlib_educ$preds
plot(VOTECON2_marketlib_educ)
```


--------------------------------------------------------------------------------


# Measures of model fit

*(documentation in progress)*

The `svyPRE` function calculates the proportional reduction in error for binary 
(`svyglm`) and ordered (`svyolr`) logit models. 

Functionality for multinomial (`svyrepstatmisc`) models is currently under development.

```{r}
svyPRE(VOTECON)
```

```{r}
svyPRE(CONLDR)
```



--------------------------------------------------------------------------------


# Planned updates

This package is under active development, and updates will include:

1. Support for (non-survey) weighted models and non-weighted models. While there 
are other packages that do this, some do not return confidence intervals for 
predictions for some model types. And, to my knowledge, none use simulation 
methods to derive confidence intervals. *Note: You can actually already do this 
with `{svyEffects}` by creating a survey design object with a weight of "1", but 
it would be good to avoid having to use that workaround.*
2. Expand functionality with `svyrepstatmisc` model objects to reduce the number 
of arguments needed to run the functions. 
3. Support for using an alternative variance-covariance matrix using `{sandwich}`. 
This would only be for binary logit models because `{sandwich}` does not play nice 
with ordinal or multinomial models. That said, survey-weighted models do adjust 
the variance-covariance matrix (the documentation for `{survey}` does not 
specify the correction method it uses, but it appears to be HC0, based on what 
I've seen). 
4. A second differences function to test for the significance of a two-way 
interaction.
5. (Eventually) Use of the delta method to calculate confidence intervals for 
AMEs  probabilities to speed up computational time.


--------------------------------------------------------------------------------


# References

Armstrong, Dave. 2022. _DAMisc: Dave Armstrong's Miscellaneous Functions._ 
R package version 1.7.2. 

Hanmer, M.J. and K.O. Kalkan.  2013. "Behind the Curve: Clarifying the Best 
Approach to Calculating Predicted Probabilities and Marginal Effects from Limited 
Dependent Variable Models." _American Journal of Political Science_. 57(1): 263-277.

Norton, Edward C., Hua Wang and Chunrong Ai. 2004. Computing Interaction Effects 
and Standard Errors in Logit and Probit Models. _The Stata Journal_ 4(2): 154-167.

Rainey, Carlisle. 2016. "Compression and Conditional Effects: A Product Term Is 
Essential When Using Logistic Regression to Test for Interaction." 
_Political Science Research and Methods_ 4(3): 621-639.

Stephenson, Laura B; Harell, Allison; Rubenson, Daniel; Loewen, Peter John, 2020, 
"2019 Canadian Election Study - Online Survey," https://doi.org/10.7910/DVN/DUS88V, 
Harvard Dataverse, V1.



--------------------------------------------------------------------------------


# Appendix: Detailed comparisons with `Stata` results

```{r, echo = FALSE}
library(readxl)
logit_b <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "logit_b")
logit_ame <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "logit_ame")
ologit_b <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "ologit_b")
ologit_ame <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "ologit_ame")
mlogit_b <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "mlogit_b")
mlogit_ame <- read_xlsx(".roughwork/comparisons.xlsx", sheet = "mlogit_ame")
```


## Binary logit

Parameter estimates and standard errors

<div style="font-size:9pt">

```{r}
logit_b
```

/div>

Predicted probabilities (AMEs)

<div style="font-size:9pt">

```{r}
logit_ame
```


</div>


## Ordered logit


Parameter estimates and standard errors

<div style="font-size:9pt">

```{r}
ologit_b
```

/div>

Predicted probabilities (AMEs)

<div style="font-size:9pt">

```{r}
ologit_ame
```


</div>


## Mulitnomial logit

For this section, there are three comparisons: 

1) `R`
2) `Stata` using `svy jackknife`
3) `Stata` using `pweight`

Parameter estimates and standard errors

<div style="font-size:9pt">

```{r}
mlogit_b
```

/div>

Predicted probabilities (AMEs)

<div style="font-size:9pt">

```{r}
mlogit_ame
```


</div>




